{
  "name": "@starter/llm",
  "version": "2.0.0",
  "description": "LLM prompt service â€” structured AI interactions with optimized prompt templates",
  "main": "dist/index.js",
  "scripts": {
    "dev": "tsx watch src/index.ts",
    "build": "tsc",
    "start": "node dist/index.js",
    "typecheck": "tsc --noEmit",
    "test": "vitest run",
    "docker": "docker compose up --build -d && KEEP_RUNNING=1 ./scripts/docker-up-build-test.sh",
    "test:watch": "vitest",
    "test:docker": "bash scripts/docker-test.sh",
    "test:integration": "bash scripts/integration-test.sh"
  },
  "dependencies": {
    "@aws-sdk/client-bedrock-runtime": "^3.750.0",
    "@google/generative-ai": "^0.24.1",
    "cors": "^2.8.6",
    "dotenv": "^17.3.1",
    "express": "^5.2.1",
    "ioredis": "^5.9.3",
    "zod": "^4.3.6"
  },
  "devDependencies": {
    "@types/cors": "^2.8.19",
    "@types/express": "^5.0.6",
    "@types/node": "^25.3.0",
    "tsx": "^4.21.0",
    "typescript": "^5.9.3",
    "vitest": "^4.0.18"
  }
}
